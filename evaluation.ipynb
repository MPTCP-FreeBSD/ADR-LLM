{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "import psutil\n",
    "import GPUtil\n",
    "from munch import Munch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from plm_special.utils.utils import process_batch\n",
    "from plm_special.data.dataset import ExperienceDataset\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "col_dict = {\n",
    "    'Throughput': 0,\n",
    "    'LossRate': 1,\n",
    "    'Latency': 2,\n",
    "    'SendingRate': 3,\n",
    "    'CCAs': 4\n",
    "}\n",
    "\n",
    "def tensor_to_list(tensor):\n",
    "        # Detach the tensor and then convert it to a NumPy array and then to a list\n",
    "        return tensor.detach().cpu().numpy().tolist()\n",
    "\n",
    "def convert_exp_pool_to_dataframe(exp_pool, csv_output_path='exp_pool_data.csv', dict_output_path='exp_pool_dict.pkl'):\n",
    "    \"\"\"\n",
    "    Converts the given experience pool into a pandas DataFrame.\n",
    "    Optionally saves the DataFrame to a CSV file and the experience pool as a dictionary to a pickle file.\n",
    "\n",
    "    Args:\n",
    "        exp_pool (object): The experience pool object containing states, actions, rewards, and dones.\n",
    "        csv_output_path (str): Path to save the resulting DataFrame as a CSV file (default: 'exp_pool_data.csv').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame representation of the experience pool.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Convert the Experience Pool to a DataFrame\n",
    "    \n",
    "    # Create state column names based on the length of each state vector\n",
    "    state_columns = [f'state_{i}' for i in range(len(exp_pool.states[0]))]  # Assuming each state is a 1D array\n",
    "    \n",
    "    # Flatten the states into individual columns\n",
    "    expanded_states = np.array([state for state in exp_pool.states])\n",
    "    \n",
    "    # Create the DataFrame with expanded states\n",
    "    df = pd.DataFrame(expanded_states, columns=state_columns)\n",
    "    \n",
    "    # Add actions, rewards, and dones as columns to the DataFrame\n",
    "    df['actions'] = exp_pool.actions\n",
    "    df['rewards'] = exp_pool.rewards\n",
    "    df['dones'] = exp_pool.dones\n",
    "\n",
    "    # Step 2: Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_output_path, index=False)\n",
    "    print(f\"DataFrame saved successfully to: {csv_output_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def find_nearest_length(df, user_input):\n",
    "    print(\"||||||||||||||||\"*40)\n",
    "    print(\"df in function find_nearest_length\")\n",
    "    if df.empty:\n",
    "        # Handle the empty DataFrame case\n",
    "        print(\"DataFrame is empty, returning None.\")\n",
    "        return None  # Return None or another suitable default value\n",
    "\n",
    "    # Calculate the absolute difference with user input\n",
    "    print(\"user_input\",user_input)\n",
    "    # nearest_idx = (df['state_6'] - user_input).abs().idxmin()\n",
    "    \n",
    "    # df_sort = df.iloc[(df['state_6']-user_input).abs().argsort()[:1]]\n",
    "    # nearest_idx = (df['state_6']-user_input).abs().argsort()[:1]\n",
    "    # print(\"df_sort\",df_sort.head(2))\n",
    "    # print(\"11nearest_idx\",nearest_idx)\n",
    "\n",
    "\n",
    "    nearest_idx = (df['state_4'] - user_input).abs().idxmin()\n",
    "    print(\"22nearest_idx\",nearest_idx)\n",
    "\n",
    "    \n",
    "\n",
    "    if nearest_idx >= len(df):\n",
    "        print(\"Outside df_ats limits\")\n",
    "    \n",
    "    if nearest_idx is None:\n",
    "        print(\"No valid index found, returning None.\")\n",
    "        return None  # Return None or another suitable default value\n",
    "    \n",
    "    print(\"||||||||||||||||\"*40)\n",
    "\n",
    "    return nearest_idx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_step(args, model, loss_fn, raw_batch, target_return):\n",
    "        # Assuming raw_batch is a tuple of numpy arrays or lists\n",
    "        states, actions, returns, timesteps = raw_batch\n",
    "\n",
    "        # # Print original state shape\n",
    "        # print(\"Original states:\", states)\n",
    "        # print(\"Original states.shape:\", states[0].shape)  # Assuming states is a list of arrays\n",
    "\n",
    "        # Convert states to tensor and ensure correct shape\n",
    "        states = torch.tensor(states[0], dtype=torch.float32).to(args.device).squeeze(-1)  # Shape [1, 8]\n",
    "        # print(\"Tensor states:\", states)\n",
    "        # print(\"Tensor states.shape:\", states.shape)  # Should be [1, 8]\n",
    "\n",
    "        # Convert actions, returns, and timesteps to tensors\n",
    "        actions = torch.tensor(actions, dtype=torch.float32).to(args.device)  # Shape [1, 1]\n",
    "        returns = torch.tensor(returns, dtype=torch.float32).to(args.device)  # Shape [1, 1]\n",
    "        timesteps = torch.tensor(timesteps, dtype=torch.int32).to(args.device)  # Shape [1, 1]\n",
    "\n",
    "        # # Print shapes after conversion\n",
    "        # print(\"Actions tensor:\", actions)\n",
    "        # print(\"Actions tensor shape:\", actions.shape)  # Should be [1, 1]\n",
    "        # print(\"Returns tensor:\", returns)\n",
    "        # print(\"Returns tensor shape:\", returns.shape)  # Should be [1, 1]\n",
    "        # print(\"Timesteps tensor:\", timesteps)\n",
    "        # print(\"Timesteps tensor shape:\", timesteps.shape)  # Should be [1, 1]\n",
    "\n",
    "        # Create a batch with the correctly formatted tensors\n",
    "        # Wrap states in a list to avoid TypeError in process_batch\n",
    "        batch = ([states], [actions], [returns], [timesteps])  # Ensure states is a list\n",
    "\n",
    "        # Call process_batch\n",
    "        states, actions, returns, timesteps, labels = process_batch(batch, device=args.device)\n",
    "\n",
    "        # Predict actions using the model\n",
    "        # actions_pred1 = model(states, actions, returns, timesteps)\n",
    "        queue_action = 0\n",
    "        actions_pred1, queue_action = model.sample(states, target_return, timesteps)\n",
    "\n",
    "        \n",
    "\n",
    "        # # Permute for loss calculation\n",
    "        # actions_pred = actions_pred1.permute(0, 2, 1)\n",
    "        # loss = loss_fn(actions_pred, labels)\n",
    "\n",
    "        # print(\"actions_pred1\",actions_pred1)\n",
    "        # print(\"actions_pred\",actions_pred)\n",
    "        # print(\"llm-queue_action\",queue_action)\n",
    "        # print(\"actual-queue_action\",labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        # return loss, states, actions, returns, timesteps, labels, actions_pred1, actions_pred\n",
    "    \n",
    "        actions_pred = actions_pred1.squeeze(-1)\n",
    "        print(\"trainepy\",self.exp_dataset_info.max_action)\n",
    "        # actions_pred = torch.sigmoid(actions_pred) * self.exp_dataset_info.max_action\\\n",
    "        # actions_pred = torch.sigmoid(actions_pred) * self.exp_dataset_info.max_action\n",
    "        # actions_pred = actions_pred * self.exp_dataset_info.max_action\n",
    "        print(\"action_pred.shape\",actions_pred.size())\n",
    "        print(\"trainerpy-actions_pred\",actions_pred)\n",
    "        labels = labels.float()\n",
    "        labels = labels / self.exp_dataset_info.max_action\n",
    "        #actions_pred = actions_pred1.permute(0, 2, 1)\n",
    "        loss = loss_fn(actions_pred, labels) \n",
    "        return loss, states, actions, returns, timesteps, labels, actions_pred1, actions_pred\n",
    "\n",
    "\n",
    "\n",
    "def otest_step(args, model, loss_fn, raw_batch, target_return):\n",
    "        # Assuming raw_batch is a tuple of numpy arrays or lists\n",
    "        states, actions, returns, timesteps = raw_batch\n",
    "\n",
    "        # # Print original state shape\n",
    "        # print(\"Original states:\", states)\n",
    "        # print(\"Original states.shape:\", states[0].shape)  # Assuming states is a list of arrays\n",
    "\n",
    "        # Convert states to tensor and ensure correct shape\n",
    "        states = torch.tensor(states[0], dtype=torch.float32).to(args.device).unsqueeze(0)  # Shape [1, 8]\n",
    "        # print(\"Tensor states:\", states)\n",
    "        # print(\"Tensor states.shape:\", states.shape)  # Should be [1, 8]\n",
    "\n",
    "        # Convert actions, returns, and timesteps to tensors\n",
    "        actions = torch.tensor(actions, dtype=torch.float32).to(args.device)  # Shape [1, 1]\n",
    "        returns = torch.tensor(returns, dtype=torch.float32).to(args.device)  # Shape [1, 1]\n",
    "        timesteps = torch.tensor(timesteps, dtype=torch.int32).to(args.device)  # Shape [1, 1]\n",
    "\n",
    "        # # Print shapes after conversion\n",
    "        # print(\"Actions tensor:\", actions)\n",
    "        # print(\"Actions tensor shape:\", actions.shape)  # Should be [1, 1]\n",
    "        # print(\"Returns tensor:\", returns)\n",
    "        # print(\"Returns tensor shape:\", returns.shape)  # Should be [1, 1]\n",
    "        # print(\"Timesteps tensor:\", timesteps)\n",
    "        # print(\"Timesteps tensor shape:\", timesteps.shape)  # Should be [1, 1]\n",
    "\n",
    "        # Create a batch with the correctly formatted tensors\n",
    "        # Wrap states in a list to avoid TypeError in process_batch\n",
    "        batch = ([states], [actions], [returns], [timesteps])  # Ensure states is a list\n",
    "\n",
    "        # Call process_batch\n",
    "        states, actions, returns, timesteps, labels = process_batch(batch, device=args.device)\n",
    "\n",
    "        # Predict actions using the model\n",
    "        # actions_pred1 = model(states, actions, returns, timesteps)\n",
    "        actions_pred1 = model(states, actions, returns, timesteps)\n",
    "\n",
    "        \n",
    "\n",
    "        # Permute for loss calculation\n",
    "        # actions_pred = actions_pred1.permute(0, 2, 1)\n",
    "        # loss = loss_fn(actions_pred, labels)\n",
    "        \n",
    "        actions_pred = actions_pred1.squeeze(-1)\n",
    "        print(\"trainepy\",self.exp_dataset_info.max_action)\n",
    "        # actions_pred = torch.sigmoid(actions_pred) * self.exp_dataset_info.max_action\\\n",
    "        # actions_pred = torch.sigmoid(actions_pred) * self.exp_dataset_info.max_action\n",
    "        # actions_pred = actions_pred * self.exp_dataset_info.max_action\n",
    "        print(\"action_pred.shape\",actions_pred.size())\n",
    "        print(\"trainerpy-actions_pred\",actions_pred)\n",
    "        labels = labels.float()\n",
    "        labels = labels / self.exp_dataset_info.max_action\n",
    "        #actions_pred = actions_pred1.permute(0, 2, 1)\n",
    "        loss = loss_fn(actions_pred, labels) \n",
    "        return loss, states, actions, returns, timesteps, labels, actions_pred1, actions_pred\n",
    "\n",
    "        queue_action = 0\n",
    "\n",
    "        # print(\"actions_pred1\",actions_pred1)\n",
    "        # print(\"actions_pred\",actions_pred)\n",
    "        # print(\"actual-queue_action\",labels)\n",
    "\n",
    "        # return loss, states, actions, returns, timesteps, labels, actions_pred1, actions_pred\n",
    "\n",
    "\n",
    "\n",
    "def testenvsim(args, model, exp_pool, target_return, loss_fn ,process_reward_fn=None, seed=0):\n",
    "    if process_reward_fn is None:\n",
    "        process_reward_fn = lambda x: x\n",
    "    \n",
    "\n",
    "    exp_dataset = ExperienceDataset(exp_pool, gamma=args.gamma, scale=args.scale, max_length=args.w, sample_step=1)\n",
    "\n",
    "    custom_logs = {'steps': []}\n",
    "\n",
    "    df =  convert_exp_pool_to_dataframe(exp_pool)\n",
    "    # print(df.columns)\n",
    "    # print(df.shape)\n",
    "    # print(df.describe())\n",
    "    # print(df.head(5))\n",
    "    # print(\"**\"*10)\n",
    "    # print(df.tail(5))\n",
    "    # print(\"*-*-\"*80)\n",
    "    # df.to_csv(\"first_save.csv\")\n",
    "\n",
    "    max_ep_len = 400\n",
    "    llm_freq = 10\n",
    "\n",
    "    row = df.iloc[0]\n",
    "    test_start = time.time()\n",
    "    cur_datapoint_idx = 0\n",
    "    start_iloc = 0\n",
    "\n",
    "    state_columns = [f'state_{i}' for i in range(len(exp_pool.states[0]))]\n",
    "    # Open the file in write mode to truncate it\n",
    "    with open('output_log.txt', 'w') as file:\n",
    "        pass  # No need to write anything, just truncating the file\n",
    "\n",
    "\n",
    "    for ep_index in range(max_ep_len):\n",
    "        # df.to_csv(\"second_save.csv\")\n",
    "        row = df.iloc[start_iloc]\n",
    "        print(\"row,\",row)\n",
    "        \n",
    "        print(\"--\" * 40)\n",
    "        state = np.array(row[state_columns], dtype=np.float32)\n",
    "        current_action = row['actions']\n",
    "        reward=row['rewards']\n",
    "        done=0\n",
    "        batch = [state],[current_action],[reward],[done]\n",
    "        # print(\"batch\",batch)\n",
    "        test_loss, states, actions, returns, timesteps, labels, actions_pred1, actions_pred = otest_step(args, model, loss_fn, batch,target_return)\n",
    "\n",
    "        # print(\"actions_pred\",actions_pred)\n",
    "        # print(\"actions_pred.shape\",actions_pred.shape)\n",
    "\n",
    "        new_action = actions_pred.detach().cpu().numpy().argmax(axis=1).flatten()\n",
    "        \n",
    "        # print(\"new_action\",new_action)\n",
    "        # print(\"type(new_action)\",type(new_action))\n",
    "\n",
    "        # print(\"new_action\",new_action.astype(int))\n",
    "        # print(\"type(new_action)\",type(new_action.astype(int)))\n",
    "\n",
    "\n",
    "        # print(\"new_action\",new_action.item())\n",
    "        # print(\"type(new_action)\",type(new_action.item()))\n",
    "\n",
    "        df_qt= df[df['state_0']== int(states[0][0][col_dict['queue_type']])]\n",
    "\n",
    "\n",
    "        \n",
    "        df_ats= df_qt[df_qt['actions']== int(new_action.item())]\n",
    "        # print(\"df_ats.head(3)\")\n",
    "        # print(df_ats.head(3))\n",
    "        # print(df_ats.describe())\n",
    "\n",
    "        # print(df_ats.head())\n",
    "        # print(\"*\"*10)\n",
    "        # print(df_qt.head())\n",
    "\n",
    "        if df_ats.empty:\n",
    "            # Save this message to a separate text file\n",
    "            # print(\"new_action\",new_action.item())\n",
    "            # print(\"queue_type\",states[0][0][0])\n",
    "            # with open(\"output_log.txt\", \"a\") as file:\n",
    "            #     file.write(str(ep_index))\n",
    "            #     file.write(\" : df_ats is empty, skipping this batch.\\n\")                \n",
    "            #     file.write(\"df_qt empty?:\")\n",
    "            #     file.write(str(df_qt.empty))\n",
    "            #     file.write(\"\\n\")\n",
    "            #     file.write(\"new_action?:\")\n",
    "            #     file.write(str(new_action.item()))\n",
    "            #     file.write(\"\\n\")\n",
    "            #     file.write(\"queue_type?:\")\n",
    "            #     file.write(str(int(states[0][0][col_dict['queue_type']])))\n",
    "            #     file.write(\"\\n\")\n",
    "            #     file.write(\"-:\"*10)\n",
    "            #     file.write(\"\\n\")\n",
    "\n",
    "            continue  # Skip to the next iteration of the loop\n",
    "        # print(\"current_queue_delay\",states[0][0][col_dict['current_queue_delay']])\n",
    "        # print(\"length_in_bytes\",states[0][0][col_dict['length_in_bytes']])\n",
    "        # print(\"packet_length\",states[0][0][col_dict['packet_length']])\n",
    "        # print(\"types(states)\",type(states))\n",
    "        new_queue_length = float(states[0][0][col_dict['length_in_bytes']])\n",
    "        print(\"new_action\",new_action.item())\n",
    "        if new_action == 0 or new_action == 2:\n",
    "            new_queue_length = (float(states[0][0][col_dict['length_in_bytes']]) + float(states[0][0][col_dict['packet_length']]))\n",
    "        cur_datapoint_idx = find_nearest_length(df_ats, new_queue_length)\n",
    "        print(\"datapoint\",cur_datapoint_idx)\n",
    "        if ep_index % llm_freq == 0:\n",
    "            start_iloc = cur_datapoint_idx\n",
    "            model.reset_dq()\n",
    "        else:\n",
    "            start_iloc+=1\n",
    "\n",
    "        # Next start datapoint of episode will be the nearest datapoint,\n",
    "        # we can find from the database\n",
    "\n",
    "        print(f'Step {ep_index} - test_loss.item() {test_loss.item()}')\n",
    "        \n",
    "        # Log step information\n",
    "        step_logs = {\n",
    "            'step': ep_index,\n",
    "            'test_loss': test_loss.item(),\n",
    "            'actions_pred1': tensor_to_list(actions_pred1),\n",
    "            'actions_pred': tensor_to_list(actions_pred),\n",
    "            'states': tensor_to_list(states),\n",
    "            'actions': tensor_to_list(actions),\n",
    "            'returns': tensor_to_list(returns),\n",
    "            'timestamps': str(time.time()),\n",
    "            'timesteps': tensor_to_list(timesteps),\n",
    "            'labels': tensor_to_list(labels)\n",
    "        }\n",
    "        custom_logs['steps'].append(step_logs)\n",
    "        \n",
    "    # Save custom logs to a JSON file for this epoch\n",
    "    with open(f'./Logs/eval_logs_llm.json', 'w') as file:\n",
    "        json.dump(custom_logs, file, indent=4)\n",
    "    start_iloc = 0\n",
    "    custom_logs = {'steps': []}\n",
    " # To Save Original Sequence\n",
    "    for ep_index in range(max_ep_len):\n",
    "        # df.to_csv(\"second_save.csv\")\n",
    "        print(\"start_iloc\",start_iloc)\n",
    "        row = df.iloc[start_iloc]\n",
    "        print(\"row,\",row)\n",
    "        \n",
    "        print(\"--\" * 40)\n",
    "        state = np.array(row[state_columns], dtype=np.float32)\n",
    "        current_action = row['actions']\n",
    "        reward=row['rewards']\n",
    "        done=0\n",
    "        batch = [state],[current_action],[reward],[done]\n",
    "        # print(\"batch\",batch)\n",
    "        test_loss, states, actions, returns, timesteps, labels, actions_pred1, actions_pred = otest_step(args, model, loss_fn, batch,target_return)\n",
    "\n",
    "\n",
    "        print(f'Step {ep_index} - test_loss.item() {test_loss.item()}')\n",
    "        \n",
    "        # Log step information\n",
    "        step_logs = {\n",
    "            'step': ep_index,\n",
    "            'test_loss': test_loss.item(),\n",
    "            'actions_pred1': tensor_to_list(actions_pred1),\n",
    "            'actions_pred': tensor_to_list(actions_pred),\n",
    "            'states': tensor_to_list(states),\n",
    "            'actions': tensor_to_list(actions),\n",
    "            'returns': tensor_to_list(returns),\n",
    "            'timestamps': str(time.time()),\n",
    "            'timesteps': tensor_to_list(timesteps),\n",
    "            'labels': tensor_to_list(labels)\n",
    "        }\n",
    "        start_iloc+=1\n",
    "        custom_logs['steps'].append(step_logs)\n",
    "    # Save custom logs to a JSON file for this epoch\n",
    "    with open(f'./Logs/eval_logs_original.json', 'w') as file:\n",
    "        json.dump(custom_logs, file, indent=4): 0,\n",
    "    'burst_allowance': 1,\n",
    "    'drop_probability': 2,\n",
    "    'current_queue_delay': 3,\n",
    "    'accumulated_probability': 4,\n",
    "    'length_in_bytes': 5,\n",
    "    'packet_length': 6\n",
    "}\n",
    "\n",
    "def tensor_to_list(tensor):\n",
    "        # Detach the tensor and then convert it to a NumPy array and then to a list\n",
    "        return tensor.detach().cpu().numpy().tolist()\n",
    "\n",
    "def convert_exp_pool_to_dataframe(exp_pool, csv_output_path='exp_pool_data.csv', dict_output_path='exp_pool_dict.pkl'):\n",
    "    \"\"\"\n",
    "    Converts the given experience pool into a pandas DataFrame.\n",
    "    Optionally saves the DataFrame to a CSV file and the experience pool as a dictionary to a pickle file.\n",
    "\n",
    "    Args:\n",
    "        exp_pool (object): The experience pool object containing states, actions, rewards, and dones.\n",
    "        csv_output_path (str): Path to save the resulting DataFrame as a CSV file (default: 'exp_pool_data.csv').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame representation of the experience pool.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Convert the Experience Pool to a DataFrame\n",
    "    \n",
    "    # Create state column names based on the length of each state vector\n",
    "    state_columns = [f'state_{i}' for i in range(len(exp_pool.states[0]))]  # Assuming each state is a 1D array\n",
    "    \n",
    "    # Flatten the states into individual columns\n",
    "    expanded_states = np.array([state for state in exp_pool.states])\n",
    "    \n",
    "    # Create the DataFrame with expanded states\n",
    "    df = pd.DataFrame(expanded_states, columns=state_columns)\n",
    "    \n",
    "    # Add actions, rewards, and dones as columns to the DataFrame\n",
    "    df['actions'] = exp_pool.actions\n",
    "    df['rewards'] = exp_pool.rewards\n",
    "    df['dones'] = exp_pool.dones\n",
    "\n",
    "    # Step 2: Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_output_path, index=False)\n",
    "    print(f\"DataFrame saved successfully to: {csv_output_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def find_nearest_length(df, user_input):\n",
    "    print(\"||||||||||||||||\"*40)\n",
    "    print(\"df in function find_nearest_length\")\n",
    "    if df.empty:\n",
    "        # Handle the empty DataFrame case\n",
    "        print(\"DataFrame is empty, returning None.\")\n",
    "        return None  # Return None or another suitable default value\n",
    "\n",
    "    # Calculate the absolute difference with user input\n",
    "    print(\"user_input\",user_input)\n",
    "    # nearest_idx = (df['state_6'] - user_input).abs().idxmin()\n",
    "    \n",
    "    # df_sort = df.iloc[(df['state_6']-user_input).abs().argsort()[:1]]\n",
    "    # nearest_idx = (df['state_6']-user_input).abs().argsort()[:1]\n",
    "    # print(\"df_sort\",df_sort.head(2))\n",
    "    # print(\"11nearest_idx\",nearest_idx)\n",
    "\n",
    "\n",
    "    nearest_idx = (df['state_6'] - user_input).abs().idxmin()\n",
    "    print(\"22nearest_idx\",nearest_idx)\n",
    "\n",
    "    \n",
    "\n",
    "    if nearest_idx >= len(df):\n",
    "        print(\"Outside df_ats limits\")\n",
    "    \n",
    "    if nearest_idx is None:\n",
    "        print(\"No valid index found, returning None.\")\n",
    "        return None  # Return None or another suitable default value\n",
    "    \n",
    "    print(\"||||||||||||||||\"*40)\n",
    "\n",
    "    return nearest_idx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_step(args, model, loss_fn, raw_batch, target_return):\n",
    "        # Assuming raw_batch is a tuple of numpy arrays or lists\n",
    "        states, actions, returns, timesteps = raw_batch\n",
    "\n",
    "        # # Print original state shape\n",
    "        # print(\"Original states:\", states)\n",
    "        # print(\"Original states.shape:\", states[0].shape)  # Assuming states is a list of arrays\n",
    "\n",
    "        # Convert states to tensor and ensure correct shape\n",
    "        states = torch.tensor(states[0], dtype=torch.float32).to(args.device).unsqueeze(0)  # Shape [1, 8]\n",
    "        # print(\"Tensor states:\", states)\n",
    "        # print(\"Tensor states.shape:\", states.shape)  # Should be [1, 8]\n",
    "\n",
    "        # Convert actions, returns, and timesteps to tensors\n",
    "        actions = torch.tensor(actions, dtype=torch.float32).to(args.device)  # Shape [1, 1]\n",
    "        returns = torch.tensor(returns, dtype=torch.float32).to(args.device)  # Shape [1, 1]\n",
    "        timesteps = torch.tensor(timesteps, dtype=torch.int32).to(args.device)  # Shape [1, 1]\n",
    "\n",
    "        # # Print shapes after conversion\n",
    "        # print(\"Actions tensor:\", actions)\n",
    "        # print(\"Actions tensor shape:\", actions.shape)  # Should be [1, 1]\n",
    "        # print(\"Returns tensor:\", returns)\n",
    "        # print(\"Returns tensor shape:\", returns.shape)  # Should be [1, 1]\n",
    "        # print(\"Timesteps tensor:\", timesteps)\n",
    "        # print(\"Timesteps tensor shape:\", timesteps.shape)  # Should be [1, 1]\n",
    "\n",
    "        # Create a batch with the correctly formatted tensors\n",
    "        # Wrap states in a list to avoid TypeError in process_batch\n",
    "        batch = ([states], [actions], [returns], [timesteps])  # Ensure states is a list\n",
    "\n",
    "        # Call process_batch\n",
    "        states, actions, returns, timesteps, labels = process_batch(batch, device=args.device)\n",
    "\n",
    "        # Predict actions using the model\n",
    "        # actions_pred1 = model(states, actions, returns, timesteps)\n",
    "        queue_action = 0\n",
    "        actions_pred1, queue_action = model.sample(states, target_return, timesteps)\n",
    "\n",
    "        \n",
    "\n",
    "        # Permute for loss calculation\n",
    "        actions_pred = actions_pred1.permute(0, 2, 1)\n",
    "        loss = loss_fn(actions_pred, labels)\n",
    "\n",
    "        print(\"actions_pred1\",actions_pred1)\n",
    "        print(\"actions_pred\",actions_pred)\n",
    "        print(\"llm-queue_action\",queue_action)\n",
    "        print(\"actual-queue_action\",labels)\n",
    "\n",
    "        return loss, states, actions, returns, timesteps, labels, actions_pred1, actions_pred\n",
    "\n",
    "\n",
    "def otest_step(args, model, loss_fn, raw_batch, target_return):\n",
    "        # Assuming raw_batch is a tuple of numpy arrays or lists\n",
    "        states, actions, returns, timesteps = raw_batch\n",
    "\n",
    "        # # Print original state shape\n",
    "        # print(\"Original states:\", states)\n",
    "        # print(\"Original states.shape:\", states[0].shape)  # Assuming states is a list of arrays\n",
    "\n",
    "        # Convert states to tensor and ensure correct shape\n",
    "        states = torch.tensor(states[0], dtype=torch.float32).to(args.device).unsqueeze(0)  # Shape [1, 8]\n",
    "        # print(\"Tensor states:\", states)\n",
    "        # print(\"Tensor states.shape:\", states.shape)  # Should be [1, 8]\n",
    "\n",
    "        # Convert actions, returns, and timesteps to tensors\n",
    "        actions = torch.tensor(actions, dtype=torch.float32).to(args.device)  # Shape [1, 1]\n",
    "        returns = torch.tensor(returns, dtype=torch.float32).to(args.device)  # Shape [1, 1]\n",
    "        timesteps = torch.tensor(timesteps, dtype=torch.int32).to(args.device)  # Shape [1, 1]\n",
    "\n",
    "        # # Print shapes after conversion\n",
    "        # print(\"Actions tensor:\", actions)\n",
    "        # print(\"Actions tensor shape:\", actions.shape)  # Should be [1, 1]\n",
    "        # print(\"Returns tensor:\", returns)\n",
    "        # print(\"Returns tensor shape:\", returns.shape)  # Should be [1, 1]\n",
    "        # print(\"Timesteps tensor:\", timesteps)\n",
    "        # print(\"Timesteps tensor shape:\", timesteps.shape)  # Should be [1, 1]\n",
    "\n",
    "        # Create a batch with the correctly formatted tensors\n",
    "        # Wrap states in a list to avoid TypeError in process_batch\n",
    "        batch = ([states], [actions], [returns], [timesteps])  # Ensure states is a list\n",
    "\n",
    "        # Call process_batch\n",
    "        states, actions, returns, timesteps, labels = process_batch(batch, device=args.device)\n",
    "\n",
    "        # Predict actions using the model\n",
    "        # actions_pred1 = model(states, actions, returns, timesteps)\n",
    "        actions_pred1 = model(states, actions, returns, timesteps)\n",
    "\n",
    "        \n",
    "\n",
    "        # Permute for loss calculation\n",
    "        actions_pred = actions_pred1.permute(0, 2, 1)\n",
    "        loss = loss_fn(actions_pred, labels)\n",
    "\n",
    "        queue_action = 0\n",
    "\n",
    "        print(\"actions_pred1\",actions_pred1)\n",
    "        print(\"actions_pred\",actions_pred)\n",
    "        print(\"actual-queue_action\",labels)\n",
    "\n",
    "        return loss, states, actions, returns, timesteps, labels, actions_pred1, actions_pred\n",
    "\n",
    "\n",
    "\n",
    "def testenvsim(args, model, exp_pool, target_return, loss_fn ,process_reward_fn=None, seed=0):\n",
    "    if process_reward_fn is None:\n",
    "        process_reward_fn = lambda x: x\n",
    "    \n",
    "\n",
    "    exp_dataset = ExperienceDataset(exp_pool, gamma=args.gamma, scale=args.scale, max_length=args.w, sample_step=1)\n",
    "\n",
    "    custom_logs = {'steps': []}\n",
    "\n",
    "    df =  convert_exp_pool_to_dataframe(exp_pool)\n",
    "    # print(df.columns)\n",
    "    # print(df.shape)\n",
    "    # print(df.describe())\n",
    "    # print(df.head(5))\n",
    "    # print(\"**\"*10)\n",
    "    # print(df.tail(5))\n",
    "    # print(\"*-*-\"*80)\n",
    "    # df.to_csv(\"first_save.csv\")\n",
    "\n",
    "    max_ep_len = 600\n",
    "    llm_freq = 10\n",
    "\n",
    "    row = df.iloc[0]\n",
    "    test_start = time.time()\n",
    "    cur_datapoint_idx = 0\n",
    "    start_iloc = 0\n",
    "\n",
    "    state_columns = [f'state_{i}' for i in range(len(exp_pool.states[0]))]\n",
    "    # Open the file in write mode to truncate it\n",
    "    with open('output_log.txt', 'w') as file:\n",
    "        pass  # No need to write anything, just truncating the file\n",
    "\n",
    "\n",
    "    for ep_index in range(max_ep_len):\n",
    "        # df.to_csv(\"second_save.csv\")\n",
    "        row = df.iloc[start_iloc]\n",
    "        print(\"row,\",row)\n",
    "        \n",
    "        print(\"--\" * 40)\n",
    "        state = np.array(row[state_columns], dtype=np.float32)\n",
    "        current_action = row['actions']\n",
    "        reward=row['rewards']\n",
    "        done=0\n",
    "        batch = [state],[current_action],[reward],[done]\n",
    "        # print(\"batch\",batch)\n",
    "        test_loss, states, actions, returns, timesteps, labels, actions_pred1, actions_pred = otest_step(args, model, loss_fn, batch,target_return)\n",
    "\n",
    "        # print(\"actions_pred\",actions_pred)\n",
    "        # print(\"actions_pred.shape\",actions_pred.shape)\n",
    "\n",
    "        new_action = actions_pred.detach().cpu().numpy().argmax(axis=1).flatten()\n",
    "        \n",
    "        # print(\"new_action\",new_action)\n",
    "        # print(\"type(new_action)\",type(new_action))\n",
    "\n",
    "        # print(\"new_action\",new_action.astype(int))\n",
    "        # print(\"type(new_action)\",type(new_action.astype(int)))\n",
    "\n",
    "\n",
    "        # print(\"new_action\",new_action.item())\n",
    "        # print(\"type(new_action)\",type(new_action.item()))\n",
    "\n",
    "        df_qt= df[df['state_0']== int(states[0][0][col_dict['queue_type']])]\n",
    "\n",
    "\n",
    "        \n",
    "        df_ats= df_qt[df_qt['states'][-1]== 0]\n",
    "        # print(\"df_ats.head(3)\")\n",
    "        # print(df_ats.head(3))\n",
    "        # print(df_ats.describe())\n",
    "\n",
    "        # print(df_ats.head())\n",
    "        # print(\"*\"*10)\n",
    "        # print(df_qt.head())\n",
    "\n",
    "        if df_ats.empty:\n",
    "            # Save this message to a separate text file\n",
    "            # print(\"new_action\",new_action.item())\n",
    "            # print(\"queue_type\",states[0][0][0])\n",
    "            # with open(\"output_log.txt\", \"a\") as file:\n",
    "            #     file.write(str(ep_index))\n",
    "            #     file.write(\" : df_ats is empty, skipping this batch.\\n\")                \n",
    "            #     file.write(\"df_qt empty?:\")\n",
    "            #     file.write(str(df_qt.empty))\n",
    "            #     file.write(\"\\n\")\n",
    "            #     file.write(\"new_action?:\")\n",
    "            #     file.write(str(new_action.item()))\n",
    "            #     file.write(\"\\n\")\n",
    "            #     file.write(\"queue_type?:\")\n",
    "            #     file.write(str(int(states[0][0][col_dict['queue_type']])))\n",
    "            #     file.write(\"\\n\")\n",
    "            #     file.write(\"-:\"*10)\n",
    "            #     file.write(\"\\n\")\n",
    "\n",
    "            continue  # Skip to the next iteration of the loop\n",
    "        # print(\"current_queue_delay\",states[0][0][col_dict['current_queue_delay']])\n",
    "        # print(\"length_in_bytes\",states[0][0][col_dict['length_in_bytes']])\n",
    "        # print(\"packet_length\",states[0][0][col_dict['packet_length']])\n",
    "        # print(\"types(states)\",type(states))\n",
    "        new_queue_length = float(states[0][0][col_dict['length_in_bytes']])\n",
    "        print(\"new_action\",new_action.item())\n",
    "        if new_action == 0 or new_action == 2:\n",
    "            new_queue_length = (float(states[0][0][col_dict['length_in_bytes']]) + float(states[0][0][col_dict['packet_length']]))\n",
    "        cur_datapoint_idx = find_nearest_length(df_ats, new_queue_length)\n",
    "        print(\"datapoint\",cur_datapoint_idx)\n",
    "        if ep_index % llm_freq == 0:\n",
    "            start_iloc = cur_datapoint_idx\n",
    "            model.reset_dq()\n",
    "        else:\n",
    "            start_iloc+=1\n",
    "\n",
    "        # Next start datapoint of episode will be the nearest datapoint,\n",
    "        # we can find from the database\n",
    "\n",
    "        print(f'Step {ep_index} - test_loss.item() {test_loss.item()}')\n",
    "        \n",
    "        # Log step information\n",
    "        step_logs = {\n",
    "            'step': ep_index,\n",
    "            'test_loss': test_loss.item(),\n",
    "            'actions_pred1': tensor_to_list(actions_pred1),\n",
    "            'actions_pred': tensor_to_list(actions_pred),\n",
    "            'states': tensor_to_list(states),\n",
    "            'actions': tensor_to_list(actions),\n",
    "            'returns': tensor_to_list(returns),\n",
    "            'timestamps': str(time.time()),\n",
    "            'timesteps': tensor_to_list(timesteps),\n",
    "            'labels': tensor_to_list(labels)\n",
    "        }\n",
    "        custom_logs['steps'].append(step_logs)\n",
    "        \n",
    "    # Save custom logs to a JSON file for this epoch\n",
    "    with open(f'./Logs/eval_logs_llm.json', 'w') as file:\n",
    "        json.dump(custom_logs, file, indent=4)\n",
    "    start_iloc = 0\n",
    "    custom_logs = {'steps': []}\n",
    " # To Save Original Sequence\n",
    "    for ep_index in range(max_ep_len):\n",
    "        # df.to_csv(\"second_save.csv\")\n",
    "        print(\"start_iloc\",start_iloc)\n",
    "        row = df.iloc[start_iloc]\n",
    "        print(\"row,\",row)\n",
    "        \n",
    "        print(\"--\" * 40)\n",
    "        state = np.array(row[state_columns], dtype=np.float32)\n",
    "        current_action = row['actions']\n",
    "        reward=row['rewards']\n",
    "        done=0\n",
    "        batch = [state],[current_action],[reward],[done]\n",
    "        # print(\"batch\",batch)\n",
    "        test_loss, states, actions, returns, timesteps, labels, actions_pred1, actions_pred = otest_step(args, model, loss_fn, batch,target_return)\n",
    "\n",
    "\n",
    "        print(f'Step {ep_index} - test_loss.item() {test_loss.item()}')\n",
    "        \n",
    "        # Log step information\n",
    "        step_logs = {\n",
    "            'step': ep_index,\n",
    "            'test_loss': test_loss.item(),\n",
    "            'actions_pred1': tensor_to_list(actions_pred1),\n",
    "            'actions_pred': tensor_to_list(actions_pred),\n",
    "            'states': tensor_to_list(states),\n",
    "            'actions': tensor_to_list(actions),\n",
    "            'returns': tensor_to_list(returns),\n",
    "            'timestamps': str(time.time()),\n",
    "            'timesteps': tensor_to_list(timesteps),\n",
    "            'labels': tensor_to_list(labels)\n",
    "        }\n",
    "        start_iloc+=1\n",
    "        custom_logs['steps'].append(step_logs)\n",
    "    # Save custom logs to a JSON file for this epoch\n",
    "    with open(f'./Logs/eval_logs_original.json', 'w') as file:\n",
    "        json.dump(custom_logs, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
